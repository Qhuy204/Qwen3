import subprocess
import time
import threading
import torch

def get_gpu_memory():
    try:
        output = subprocess.check_output(
            ["nvidia-smi", "--query-gpu=memory.used", "--format=csv,noheader,nounits"],
            encoding="utf-8"
        )
        return int(output.strip())
    except:
        return 0

vram_log = []
stop_event = threading.Event()

def monitor():
    while not stop_event.is_set():
        vram_log.append(get_gpu_memory())
        time.sleep(0.1)

# Khá»Ÿi Ä‘á»™ng monitor
initial_vram = get_gpu_memory()
monitor_thread = threading.Thread(target=monitor)
monitor_thread.start()

print(f"ğŸ“Š VRAM ban Ä‘áº§u: {initial_vram} MiB")
print("ğŸš€ Äang cháº¡y inference (LoRA Native)...")

try:
    # Cháº¡y láº¡i script predict Ä‘Ã£ test thÃ nh cÃ´ng cá»§a báº¡n
    cmd = [
        "python", "inference/predict.py",
        "--image", "/home/qhuy/Qwen3/test_landmark.jpg",
        "--question", "Bá»©c áº£nh nÃ y á»Ÿ Ä‘Ã¢u?",
        "--lora-path", "/home/qhuy/Qwen3/outputs/Qwen3-VL8B"
    ]
    subprocess.run(cmd, check=True)
except Exception as e:
    print(f"âŒ Lá»—i khi cháº¡y inference: {e}")

# Dá»«ng monitor
stop_event.set()
monitor_thread.join()

peak_vram = max(vram_log) if vram_log else initial_vram
print("\n" + "="*50)
print(f"ğŸ”¥ PEAK VRAM (Native LoRA): {peak_vram} MiB (~{peak_vram/1024:.2f} GB)")
print(f"ğŸ“ˆ Dung lÆ°á»£ng sá»­ dá»¥ng thÃªm: {peak_vram - initial_vram} MiB")
print(f"âœ… Tráº¡ng thÃ¡i: RTX 3060 (12GB) cÃ²n dÆ° {(12288 - peak_vram)/1024:.2f} GB")
print("="*50)
